# 現在の知識レベル

## 既知の概念

### 機械学習基礎
- ニューラルネットワークの基本構造
- 逆伝播アルゴリズム
- 損失関数と最適化手法
- 教師あり学習、教師なし学習の概念

### LLM関連概念（概要レベル）
- **Transformer**: 名前と基本的な概念は理解済み
- **Encoder/Decoder**: 構造の概要は把握済み
- **Attention Mechanism**: 概念は理解しているが詳細は未習得

### 数学的背景
- 線形代数の基礎（行列演算、ベクトル空間）
- 微分・積分の基本概念
- 確率・統計の大まかな理解

### 実務経験
- Microsoft でのエンジニア業務
- AI勉強会の主催・運営経験
- 技術的なコミュニケーション能力

## 不明確な概念

### アーキテクチャの詳細
- Transformer の内部構造の詳細
- Multi-head attention の具体的な動作
- Position encoding の種類と選択基準
- Layer normalization vs Batch normalization の使い分け

### トレーニングプロセス
- Pre-training と Fine-tuning の具体的な違い
- RLHF（人間フィードバック強化学習）の仕組み
- Gradient accumulation や Mixed precision の効果

### ハイパーパラメータ
- Learning rate schedule の設定方法
- Batch size が性能に与える影響
- Temperature parameter の調整基準
- Sequence length の最適化

### 数学的詳細
- **偏微分**: さらなる学習が必要（自己申告）
- Attention weight の計算過程
- Softmax 関数の性質と調整方法

## 未知の概念

### 最新技術動向
- GPT-4、Claude、Gemini の具体的な技術的差異
- In-context learning の詳細メカニズム
- Chain-of-thought prompting の理論的背景

### 実装技術
- Hugging Face Transformers library の詳細使用法
- 量子化技術（8-bit、4-bit）の原理と実装
- 推論最適化技術（KV-cache、speculative decoding）

### 評価手法
- BLEU、ROUGE、BERTScore等の評価指標
- Human evaluation の設計方法
- A/B testing for LLM applications

### ツールとフレームワーク
- LangChain、LlamaIndex等の RAG フレームワーク
- Vector databases（Pinecone、Weaviate等）
- MLOps tools for LLM deployment

## 経験・実践

### 関連業務経験
- Microsoft でのエンジニア業務（AI/ML関連プロジェクト関与の可能性）
- 技術的な議論やレビューへの参加
- チーム内での技術共有やメンタリング

### 教育・コミュニケーション経験
- シアトルAI勉強会の主催・運営
- 技術的内容の分かりやすい説明経験
- 多様な背景を持つ参加者への対応

### 学習・研究経験
- 継続的な技術学習の習慣
- 新しい技術動向のキャッチアップ
- 理論と実践のバランスを取った学習アプローチ
