# LLM Fundamentals - メタデータ

## 基本情報
- **学習分野**: LLM（Large Language Model）の基礎概念
- **作成日**: 2025年7月10日
- **学習者の背景**: Microsoftエンジニア、シアトルAI勉強会主催者
- **現在の知識レベル**: 機械学習の基礎理解済み、Transformer等の概要は理解済み

## 学習目的
- **業務活用**: Microsoft での技術的議論への参加と裏付け知識の獲得
- **教育活動**: シアトルAI勉強会での分かりやすい説明能力の向上
- **実践応用**: モデル選定やハイパーパラメータ設定の理論的根拠の理解

## 学習範囲
- Transformer architecture の詳細理解
- Attention mechanism（Self-attention, Multi-head attention）
- Pre-training と Fine-tuning の仕組み
- Tokenization, Embedding, Position Encoding
- ハイパーパラメータとその役割
- 関連ツールとトレーニング手法
- 最新論文の概要理解レベル

## 最終目標
1. **説明能力**: 同僚にLLMの仕組みを分かりやすく説明できる
2. **実装理解**: ハイパーパラメータの役割を理解してモデル選定・設定ができる
3. **技術議論**: 会社での技術的議論に理論的根拠を持って参加できる
4. **論文理解**: 最新論文（GPT-4、Claude、Gemini等）の概要を理解できる

## 学習方法の希望
- **理論と実践のバランス**: 数式は参考程度、概念理解と実用性重視
- **実例重視**: 具体的なツールや実装例を交えた学習
- **段階的理解**: 基礎から応用へと段階的に積み上げ
